

        "test_df.rename(columns={'OrdinalRank': 'Team2OrdinalRank'}, inplace=True)\n",
        "test_df.drop('TeamID', axis=1, inplace=True)\n",
        "\n",
        "# 6. Calculate 'SeedDiff' and 'OrdinalRankDiff'\n",
        "test_df['SeedDiff'] = test_df['Team1SeedInt'] - test_df['Team2SeedInt']\n",
        
      },
      "source": [
        "The XGBoost model has been successfully retrained with both 'SeedDiff' and 'OrdinalRankDiff' features. Now, I will generate predictions for the test set using the updated model and the prepared `X_test_final` features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82646005"
      },
      "source": [
        "test_df['Pred'] = model.predict_proba(X_test_final)[:, 1]\n",
        "print(\"Predictions generated for the test set.\")\n",
        "print(test_df[['ID', 'Pred']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "594c6910"
      },
      "source": [
        "The next step in the task is to apply prediction clipping to the generated probabilities to keep them within a reasonable range (0.025 to 0.975), which helps to avoid extreme probabilities and improve robustness in submission files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20702145"
      },
      "source": [
        "test_df['Pred'] = np.clip(test_df['Pred'], 0.025, 0.975)\n",
        "print(\"Predictions clipped successfully.\")\n",
        "print(test_df[['ID', 'Pred']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5252f476"
      },
      "source": [
        "The predictions have been generated and clipped. The final step of the task is to format these predictions into the required submission file format, which means selecting the 'ID' and 'Pred' columns from `test_df` and saving them to `submission.csv`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc1e69ae"
      },
      "source": [
        "submission = test_df[['ID', 'Pred']]\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Made successful! Ensembled submission.csv saved!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "def6b8e5"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The `SampleSubmissionStage2.csv` file was successfully loaded, providing the template for the submission.\n",
        "*   Test features, including `Season`, `Team1ID`, `Team2ID`, seed information (`Team1SeedInt`, `Team2SeedInt`), and ordinal ranks (`Team1OrdinalRank`, `Team2OrdinalRank`), were extracted and merged for both teams in each matchup.\n",
        "*   Differences in seeds (`SeedDiff`) and ordinal ranks (`OrdinalRankDiff`) were calculated for the test set.\n",
        "*   Missing values (NaNs) in seed and ordinal rank features, particularly for future seasons, were identified and filled with `0`.\n",
        "*   An initial attempt to generate predictions failed due to a feature mismatch: the model was trained with only `SeedDiff`, while the test data contained both `SeedDiff` and `OrdinalRankDiff`.\n",
        "*   During the process of resolving the feature mismatch, it was discovered that the `OrdinalRankDiff` feature was missing from the `final_data` used for model training. This was corrected by explicitly calculating `OrdinalRankDiff` as `LOrdinalRank - WOrdinalRank` in the training data.\n",
        "*   The XGBoost model was successfully retrained using both `SeedDiff` and `OrdinalRankDiff` as features.\n",
        "*   Predictions were generated for the test set using the retrained model and then clipped to the range of \\[0.025, 0.975] to regularize extreme probability values.\n",
        "*   The final `submission.csv` file was successfully created and saved, containing the `ID` and `Pred` columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52ac9ed5"
      },
      "source": [
        "## Identify Men's and Women's Matchups\n",
        "\n",
        "Based on the `Team1ID` (or `Team2ID`), identify which entries in `test_df` correspond to men's tournament games and which correspond to women's tournament games. Men's TeamIDs are typically below 3000, while Women's TeamIDs are 3000 or above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ae1ffe9"
      },
      "source": [
        "men_test_df = test_df[test_df['Team1ID'] < 3000].copy()\n",
        "women_test_df = test_df[test_df['Team1ID'] >= 3000].copy()\n",
        "\n",
        "print(\"Men's and women's test dataframes created.\")\n",
        "print(\"Men's test data (head):\\n\", men_test_df.head())\n",
        "print(\"\\nWomen's test data (head):\\n\", women_test_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "men_submission = men_test_df[['ID', 'Pred']]\n",
        "men_submission.to_csv('men_submission.csv', index=False)\n",
        "\n",
        "women_submission = women_test_df[['ID', 'Pred']]\n",
        "women_submission.to_csv('women_submission.csv', index=False)\n",
        "\n",
        "print(\"Men's and women's submission files generated successfully!\")"
      ],
      "metadata": {
        "id": "-PFDWBO7qNLk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
